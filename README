This is a bourne shell rewrite of the existing cbuild system as used by Linaro.

Configuring Cbuildv2:
---------------------
  WHile it is possible to run cbuildv2 from it's source tree, this
isn't recommended. The best practice is to create a new build
directory, and configure cbuildv2 in that directory. That makes it
wasy to change branches, or even delete subdirectories easily. There
are defaults for all 

$CBUILD-PATH/configure
--with-local-snapshots=$CBUILD_PATH/snapshots 
--with-local-builds=$CBUILD-PATH/depends 
--with-remote-snapshots=cbuild@toolchain64.lab:/home/cbuild/var/snapshots/

Specifying the source works like this:
-------------------------------------
It's possible to specify a full tarball name, minus the compression
part, which will be found dynamically. If the word 'tar' appears in
the suppplied name, it's only looked for on the remote directory. If
the name is a URL for bzr, sv, http, or git, the the source are
instead checked out from a remote repository instead with the
appropriate source code control system.

It's also possible to specify an 'alias', ie ... 'gcc-4.8' instead. In
this case, the remote snapshot directory is checked first. If the name
is not unique, but matches are found, and error is generated. If the
name isn't found at all, then a URL for the source repository is
extracted from the sources.conf file, and the code is checkout out.

There are a few ways if listing the files to see what is
available. There ar two primary remote directories where files that
can be downloaded are stored. These are 'snapshots' or
'infrastructure'. Infrastructure is usualy only installed once per
host, and contains the other packages needed to build GCC, like
gmp. Snapshots is the primary location of all source tarballs. To list
all the available snapshots, you can do this

    "cbuild2.sh --list snapshots".

You can also run cbuildv2 with the --interactive options, which will
display a subset of all the packages that matches the supplied
string. To build a specific component, use the --build option to
cbuildv2. the --target option is also used for cross builds. For
example:

"cbuild2.sh --target arm-none-linux-gnueabihf gcc-linaro-4.8.2013.07-1"

This would fetch the source tarball for this release, build anything
it needs to compile, the binutils for example, and then build these
sources. You can also specify a URL to a source repository
instead. For example:

"cbuild2.sh --target arm-none-linux-gnueabihf git://git.linaro.org/toolchain/eglibc.git"

To build and entire cross toolchain, the simplest way is to let
cbuildv2 control allthe steps, although it is also possible to do each
step separately. To build the full toolchain, do this:

"cbuild2.sh --target arm-none-linux-gnueabihf --build all"

---------------------------------------------------------------------
x86_64-none-linux-gnu
arm-none-linux-gnueabi
arm-none-linux-gnueabihf
aarch64-none-linux-gnu
aarch64-none-elf
arm-none-linux-gnueabi
arm-none-linux-gnueabihf
armeb-none-linux-gnueabihf
aarch64_be-none-elf
aarch64_be-none-linux-gnu

Toolchain Components
 * gcc (gcc, g++, objc, fortran)
 * gas
 * ld (gold)
 * libc (newlib,eglibc,glibc)
 * dependant libs (gmp, mpc, mpfr, libelf)

Build with stock Ubuntu toolchains
 * Linaro GCC Maintenance (currently Linaro GCC 4.7)
 * FSF GCC Previous (currently FSF GCC 4.7)
 * FSF GCC Current (currently FSF GCC 4.8)

Build with trunk/master
 * Linaro GCC Development (currently Linaro GCC 4.8)
 * FSF GCC Trunk (currently FSF GCC 4.9)

Variables
 * build machine toolchain versions of all components (gcc, gas, ld, libc)
 * configure options

Features:
---------
 * Build with downloaded binaries or build them all locally
 * Has default configuration for all components
 * All info recorded into an SQL database
 * Ability to mix & match all toolchain components
 * Test locally or remotely
 * Queue jobs for LAVA
 * Lists possible versions and components for build

cbuild2 command line arguments:
-------------------------------
 * --build (architecture for the build machine, default native)
 * --target (architecture for the target machine, default native)
 * --snapshots XXX (URL of remote host or local directory)
 * --libc {newlib,eglibc,glibc} (C library to use)
 * --list {gcc,binutils,libc} (list possible values for component versions)
 * --set {gcc,binutils,libc,latest}=XXX (change config file setting)
 * --binutils (binutils version to use, default $PATH)
 * --gcc (gcc version to use, default $PATH)
 * --config XXX (alternate config file)
 * --clean (clean a previous build, default is to start where it left off)
 * --dispatch (run on LAVA build farm, probably remote)
 * --sysroot XXX (specify path to alternate sysroot)


General ideas
-------------
Use a shell script as config file, ala *.conf and set global
variables or custom functions. A good naming convention to avoid
collisions is important. It should be able to be download from a
remote host. 

Rather than Makefiles, it should use bourne shell scripts for more
functionality. Both Android and Chromium use this technique.

Each project that needs to be built should have a file that lists it's
major build time dependancies. There should be defaults for all
targets, but values can be overridden with local config files. The
config data could also potentially live in a database. The config data
is recorded into the database for each build and test run.

Cross building G++ is complex, there is a stage 1 build of the
compiler, which is only used to build the C library. Then the C
library is compiled. After that G++ can be built.
 
Analysis
--------

The main goal is to have the appropriate data accessible to support
charting it in various ways to assist in better understanding of the
quality of each toolchain component. This will assist developers in
determining if their changes improve or degrade the component's
quality. This will also allow others to get an overview of each
component's quality, which will support product releases and
management planning.

 * Plot a test run of a specific version of a component across all
   supported platforms
 * Plot a test case of a component across all supported platforms
 * Plot a test case of a component across a list of versions
 * Plot a component's PASS percentage across all supported platforms
 * Plot a component's PASS percentage across all supported platforms
   and several versions.
 * Plot a component's FAIL percentage across all supported platforms
 * Plot a component's FAIL percentage across all supported platforms
   and several versions.
 * Plot all test states as a percentage of total test results
 * Plot all test states of the actual totals for each
 * 


CREATE TABLE `benchmarks` (
  `date` datetime NOT NULL,
  `benchmark` varchar(72) NOT NULL,
  `result` time NOT NULL,
  `version` varchar(72) NOT NULL,
  `status` enum('IDLE','RUNNING','DONE') NOT NULL,
  `target_arch` varchar(72) NOT NULL,
  `build_arch` varchar(72) NOT NULL,
  `gcc_version` varchar(72) NOT NULL,
  `binutils_version` varchar(72) NOT NULL,
  `libc_version` varchar(72) NOT NULL,
  `enabled_cores` INT(20) NOT NULL,
  `enabled_chips` INT(20) NOT NULL,
  `cores_per_chip` INT(20) NOT NULL,
  `threads_per_core` INT(20) NOT NULL,
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

CoreMark
 * Compiler and version
 * Operating Speed in Mhz
 * CoreMark/Mhz
 * CoreMark
 * CoreMark/Core
 * Parallel Execution
 * EEMBC

EEMBC
 * TODO

Spec CPU 2000
 * CINT
  * Benchmark
  * Reference Time
  * Base Runtime
  * Base Ratio
  * Runtime
  * Ratio
 * CFP
  * Benchmark
  * Reference Time
  * Base Runtime
  * Base Ratio
  * Runtime
  * Ratio

Spec CPU 2006
 * Benchmark
 * Base Seconds
 * Base Ratio
 * Peak Seconds
 * Peak Ratio

Notes on Bourne Shell Scripting
-------------------------------

  These scripts use a few techniques in many places that relate to
shell functions. One is heavy use of bourne shell functions to reduce
duplication, and make the code better organized. Any string echo'd by
a function becomes it's return value. Bourne shell supports 2 types of
return values though. One is the string returned by the function. This
is used whenever the called function returns data. This is captured by
the normal shell commands like this: values="`call_function $1`". The
other type of return value is a single integer. Much like system
calls, these scripts all return 0 for success, and 1 for errors. This
enables the calling function to trap errors, and handle them in a
clean fashion.

  A few good habits to mention, always enclose a sub shell execution
in double quotes. If the returned string contains spaces, this
preserves the data, otherwise it'll get truncated.

  Another good habit is to always prepend a character when doing
string comparisons. If one of the two strings is undefined, the script
will abort. So always using "test x${foo} = xbar" prevents that.

